# agentic_rag_pipeline/inspector_app.py (‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô Control Room)

from graph_agent.graph import graph_app
import os
import streamlit as st
import pandas as pd
import psycopg2
import tempfile
import pprint

# --- Import ‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå Agent ‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤ ---
# ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏Å‡∏≤‡∏£ Import ‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÅ‡∏•‡πâ‡∏ß
import config
from graph_agent.graph import graph_app

# --- Database Connection Function (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ---
@st.cache_resource
def get_db_connection():
    try:
        conn = psycopg2.connect(
            dbname=config.DB_NAME, user=config.DB_USER, password=config.DB_PASS,
            host=config.DB_HOST, port=config.DB_PORT
        )
        return conn
    except psycopg2.OperationalError as e:
        st.error(f"‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}")
        return None

# --- Main App ---
st.set_page_config(layout="wide", page_title="Agent Pipeline Inspector")
st.title("üî¨ Agentic Pipeline Inspector & Control Room")

conn = get_db_connection()
if not conn:
    st.error("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö .env ‡πÅ‡∏•‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Ç‡∏≠‡∏á Docker")
    st.stop()

# --- ‡∏™‡∏£‡πâ‡∏≤‡∏á Tabs ---
tab_control, tab_bots, tab_kb, tab_chunks = st.tabs([
    "üïπÔ∏è Agent Control Room", "ü§ñ Bot & Persona Inspector",
    "üìö Knowledge Base Inspector", "üß© Chunk Viewer"
])

# ==============================================================================
# TAB 1: AGENT CONTROL ROOM (‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏ó‡∏£‡∏á‡∏û‡∏•‡∏±‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î!)
# ==============================================================================
with tab_control:
    st.header("üïπÔ∏è ‡∏™‡∏±‡πà‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á LangGraph Agent")
    st.markdown("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏° Pipeline ‡πÅ‡∏•‡∏∞‡∏î‡∏π‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á Agent ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡πÅ‡∏ö‡∏ö Real-time")

    uploaded_file = st.file_uploader(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ (.pdf, .docx, .txt) ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•",
        type=['pdf', 'docx', 'txt']
    )

    if uploaded_file is not None:
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á temporary file ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ Agent ‡∏°‡∏µ path ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå
        with tempfile.NamedTemporaryFile(delete=False, suffix=f"_{uploaded_file.name}") as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            file_path = tmp_file.name
        
        st.info(f"‡πÑ‡∏ü‡∏•‡πå‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ó‡∏µ‡πà: `{file_path}`")

        if st.button("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á Agent", use_container_width=True, type="primary"):
            st.markdown("---")
            st.subheader("üî¥ LIVE: ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á Agent")
            status_container = st.container()

            # --- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° "‡∏ñ‡∏≤‡∏î" (State) ‡πÉ‡∏ö‡πÅ‡∏£‡∏Å ---
            initial_state = {
                "file_path": file_path,
                "original_filename": os.path.basename(file_path), # <-- ‡πÄ‡∏û‡∏¥‡πà‡∏° OS.PATH
                "clean_text": "",
                "metadata": {},
                "chunks": [],
                "error_message": None,
                "layout_map": {},        # <-- [V2] Field ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
                "validation_passes": 0,
                "retry_history": []      # <-- [V5] Field ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô (‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà chunking_retries)
            }

            try:
                
                for step in graph_app.stream(initial_state):
                    # `step` ‡∏Ñ‡∏∑‡∏≠ Dictionary ‡∏ó‡∏µ‡πà‡∏°‡∏µ key ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠ Node ‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à
                    node_name = list(step.keys())[0]
                    node_state = step[node_name]

                    with status_container:
                        with st.expander(f"**‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ: `{node_name}`** - ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô", expanded=True):
                            
                            # --- [V5+V2] Smart Display Logic ---
                            if node_name == "layout_analysis":
                                st.markdown("##### üó∫Ô∏è ‡πÅ‡∏ú‡∏ô‡∏ú‡∏±‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á (Layout Map)")
                                st.json(node_state.get("layout_map", {}))
                            
                            elif node_name == "validate_chunks":
                                st.markdown("##### ü©∫ ‡πÅ‡∏ü‡πâ‡∏°‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤ (Retry History)")
                                st.json(node_state.get("retry_history", []))
                                if node_state.get("validation_passes", 0) > 0:
                                    st.success("-> ‚úÖ ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏ú‡πà‡∏≤‡∏ô!")
                                if node_state.get("error_message"):
                                    st.error(f"-> üõë ‡∏¢‡∏≠‡∏°‡πÅ‡∏û‡πâ: {node_state.get('error_message')}")
                            
                            elif node_name == "chunker":
                                st.markdown(f"##### üß© ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö Chunks ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(node_state.get('chunks', []))} ‡∏ä‡∏¥‡πâ‡∏ô")
                            
                            else:
                                # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô Node ‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏°
                                st.code(pprint.pformat(node_state), language="json")

                st.success("üéâ Pipeline ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå!")

            except Exception as e:
                st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡πâ‡∏≤‡∏¢‡πÅ‡∏£‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á Agent: {e}")
            finally:
                # ‡∏•‡∏ö temporary file ‡∏ó‡∏¥‡πâ‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à
                if os.path.exists(file_path):
                    os.remove(file_path)


# ==============================================================================
# TAB 2: BOT & PERSONA INSPECTOR (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
# ==============================================================================
with tab_bots:
    st.header("ü§ñ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏° Bots ‡πÅ‡∏•‡∏∞ Personas")
    st.markdown("‡∏î‡∏π‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏ö‡∏≠‡∏ó‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö ‡πÅ‡∏•‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å‡∏†‡∏≤‡∏û (Prompts) ‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")

    try:
        # Query ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Bot ‡πÅ‡∏•‡∏∞ Persona ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£ JOIN ‡∏™‡∏≠‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á
        query = """
            SELECT
                b.id as bot_id,
                b.bot_name,
                b.api_key,
                b.qdrant_collection_name,
                b.is_active,
                p.id as persona_id,
                p.persona_name,
                p.system_prompt,
                p.routing_prompt,
                p.refusal_message,
                p.about_bot_message
            FROM bots b
            LEFT JOIN bot_personas p ON b.persona_id = p.id
            ORDER BY b.id;
        """
        bots_df = pd.read_sql(query, conn)

        st.success(f"‡∏û‡∏ö **{len(bots_df)}** ‡∏ö‡∏≠‡∏ó‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö")

        # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏ö‡∏≠‡∏ó
        st.dataframe(
            bots_df[['bot_id', 'bot_name', 'api_key', 'qdrant_collection_name', 'is_active', 'persona_name']],
            use_container_width=True,
            hide_index=True
        )

        st.divider()
        st.subheader("üîç ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î Persona (Prompts)")

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á Expander ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ Persona ‡∏ó‡∏µ‡πà‡∏û‡∏ö
        for index, row in bots_df.iterrows():
            with st.expander(f"**{row['bot_name']}** (Persona: '{row['persona_name']}')"):
                st.markdown(f"**Bot ID:** `{row['bot_id']}` | **API Key:** `{row['api_key']}`")
                st.text_area("System Prompt (‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å‡∏´‡∏•‡∏±‡∏Å)", row['system_prompt'], height=200, disabled=True, key=f"sys_{index}")
                st.text_area("Routing Prompt (‡∏ï‡∏±‡∏ß‡∏à‡∏±‡∏î‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó)", row['routing_prompt'], height=200, disabled=True, key=f"route_{index}")
                st.text_area("Refusal Message (‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏è‡∏¥‡πÄ‡∏™‡∏ò)", row['refusal_message'], height=100, disabled=True, key=f"refuse_{index}")
                st.text_area("About Bot Message (‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏±‡∏ß)", row['about_bot_message'], height=100, disabled=True, key=f"about_{index}")

    except Exception as e:
        st.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Bots ‡πÅ‡∏•‡∏∞ Personas ‡πÑ‡∏î‡πâ: {e}")



# ==============================================================================
# TAB 3 & 4: KNOWLEDGE BASE & CHUNK VIEWER (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
# ==============================================================================
with tab_kb:
    st.header("üìö ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏ô `knowledge_items`")
    try:
        items_df = pd.read_sql("SELECT id, title, source_type, status, created_at FROM knowledge_items ORDER BY id DESC", conn)
        st.dataframe(items_df, use_container_width=True, hide_index=True)
    except Exception as e:
        st.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• knowledge_items ‡πÑ‡∏î‡πâ: {e}")


with tab_chunks:
    st.header("üß© ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡πà‡∏≠‡∏¢ (Chunk Viewer)")
    item_id_to_view = st.number_input(
        "‡πÉ‡∏™‡πà ID ‡∏Ç‡∏≠‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏î‡∏π Chunks (‡∏î‡∏π ID ‡∏à‡∏≤‡∏Å‡∏ï‡∏≤‡∏£‡∏≤‡∏á 'Knowledge Base Inspector')",
        min_value=1,
        step=1
    )
    if st.button("üî¨ ‡πÅ‡∏™‡∏î‡∏á Chunks", use_container_width=True):
        if item_id_to_view > 0:
            try:
                chunks_df = pd.read_sql(
                    "SELECT chunk_sequence, chunk_text, metadata FROM knowledge_chunks WHERE knowledge_item_id = %s ORDER BY chunk_sequence",
                    conn,
                    params=(item_id_to_view,)
                )
                st.info(f"‡∏û‡∏ö **{len(chunks_df)}** Chunks ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ ID: {item_id_to_view}")

                for index, row in chunks_df.iterrows():
                    chunk_length = len(row['chunk_text'])
                    expander_title = f"Chunk #{row['chunk_sequence']} (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß: {chunk_length} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£)"
                    with st.expander(expander_title):
                        st.text_area("Content", row['chunk_text'], height=200, disabled=True, key=f"chunk_detail_{index}")
                        st.json(row['metadata'])

            except Exception as e:
                st.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î Chunks ‡πÑ‡∏î‡πâ: {e}")